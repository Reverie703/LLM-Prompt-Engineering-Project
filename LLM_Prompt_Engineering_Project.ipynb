{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e96ff-f42c-4a97-9f87-bd94c68fbd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "qa_categories = {\n",
    "    \"math\": [\n",
    "        (\"What is {a} + {b}?\", lambda a, b: str(a + b)),\n",
    "        (\"What is {a} - {b}?\", lambda a, b: str(a - b)),\n",
    "        (\"What is {a} * {b}?\", lambda a, b: str(a * b)),\n",
    "        (\"What is the square of {a}?\", lambda a: str(a ** 2)),\n",
    "        (\"What is the cube of {a}?\", lambda a: str(a ** 3)),\n",
    "    ],\n",
    "    \"gk\": [\n",
    "        (\"What is the capital of India?\", \"New Delhi\"),\n",
    "        (\"Who wrote Hamlet?\", \"William Shakespeare\"),\n",
    "        (\"What is the currency of Japan?\", \"Yen\"),\n",
    "        (\"Who discovered gravity?\", \"Isaac Newton\"),\n",
    "        (\"What is the largest planet?\", \"Jupiter\"),\n",
    "    ],\n",
    "    \"science\": [\n",
    "        (\"What gas do plants absorb?\", \"Carbon dioxide\"),\n",
    "        (\"What is H2O commonly known as?\", \"Water\"),\n",
    "        (\"What is the boiling point of water?\", \"100°C\"),\n",
    "        (\"Who invented the light bulb?\", \"Thomas Edison\"),\n",
    "        (\"What organ pumps blood in the human body?\", \"Heart\"),\n",
    "    ],\n",
    "    \"grammar\": [\n",
    "        (\"Is 'quickly' a noun or adverb?\", \"Adverb\"),\n",
    "        (\"Give a synonym for 'smart'.\", \"Intelligent\"),\n",
    "        (\"What is the opposite of 'happy'?\", \"Sad\"),\n",
    "        (\"Is 'run' a verb in 'I run daily'?\", \"Yes\"),\n",
    "        (\"What is the past tense of 'eat'?\", \"Ate\"),\n",
    "    ],\n",
    "    \"logic\": [\n",
    "        (\"What comes after 2, 4, 6, 8?\", \"10\"),\n",
    "        (\"Is every even number divisible by 2?\", \"Yes\"),\n",
    "        (\"If A > B and B > C, is A > C?\", \"Yes\"),\n",
    "        (\"If you have 4 apples and give away 2, how many are left?\", \"2\"),\n",
    "        (\"Is 121 a square number?\", \"Yes\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "qa_dataset = []\n",
    "for _ in range(8000):  # Use 8000 entries\n",
    "    category = random.choice(list(qa_categories.keys()))\n",
    "    entry = random.choice(qa_categories[category])\n",
    "    \n",
    "    if callable(entry[1]):\n",
    "        if \"{a}\" in entry[0] and \"{b}\" in entry[0]:\n",
    "            a, b = random.randint(1, 50), random.randint(1, 50)\n",
    "            question = entry[0].format(a=a, b=b)\n",
    "            answer = entry[1](a, b)\n",
    "        else:\n",
    "            a = random.randint(1, 20)\n",
    "            question = entry[0].format(a=a)\n",
    "            answer = entry[1](a)\n",
    "    else:\n",
    "        question, answer = entry\n",
    "\n",
    "    qa_dataset.append({\"text\": f\"Q: {question}\\nA: {answer}\"})\n",
    "\n",
    "# Save the dataset\n",
    "with open(\"qa_decoder_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in qa_dataset:\n",
    "        json.dump(item, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"Decoder-friendly dataset with 8000 entries saved as 'qa_decoder_dataset.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a5a762-e73b-40a2-af29-a74639764fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the dataset\n",
    "data = []\n",
    "with open(\"qa_decoder_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line.strip())\n",
    "        data.append(item[\"text\"])\n",
    "\n",
    "print(f\"Loaded {len(data)} examples.\")\n",
    "print(\"Sample:\", data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d3df8-d78f-4999-a366-765bf82b1c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class GPTStyleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=256, num_heads=4, num_layers=4, dropout=0.1, max_length=128):\n",
    "        super(GPTStyleTransformer, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, embed_dim)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        device = input_ids.device\n",
    "        seq_len = input_ids.size(1)\n",
    "\n",
    "        positions = torch.arange(0, seq_len, device=device).unsqueeze(0)\n",
    "        x = self.token_embedding(input_ids) + self.pos_embedding(positions)\n",
    "\n",
    "        # Generate mask with correct shape based on input length\n",
    "        causal_mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(device)\n",
    "\n",
    "        x = self.transformer(x.transpose(0, 1), mask=causal_mask)  # shape: [seq_len, batch, embed]\n",
    "        x = x.transpose(0, 1)  # back to [batch, seq_len, embed]\n",
    "\n",
    "        return self.output_layer(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed7dfa-fc23-40b2-9b2e-7aa04ffe72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load a tokenizer (distilgpt2 is a small GPT-compatible tokenizer)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Required for padding support\n",
    "\n",
    "class QADecoderDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.examples = []\n",
    "\n",
    "        for text in texts:\n",
    "            encoding = tokenizer(\n",
    "                text,\n",
    "                max_length=max_length,\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            input_ids = encoding[\"input_ids\"].squeeze()\n",
    "            attention_mask = encoding[\"attention_mask\"].squeeze()\n",
    "            self.examples.append((input_ids, attention_mask))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, attention_mask = self.examples[idx]\n",
    "        labels = input_ids.clone()\n",
    "        return input_ids, attention_mask, labels\n",
    "\n",
    "# Prepare dataset and dataloader\n",
    "dataset = QADecoderDataset(data, tokenizer)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "print(\"Tokenizer and dataset ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2635878-61a2-499b-ac6a-cc55c6d13300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# Initialize model and optimizer\n",
    "model = GPTStyleTransformer(vocab_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "# Training loop\n",
    "EPOCHS = 9\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    for input_ids, attention_mask, labels in tqdm(loader, desc=\"Training\"):\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "\n",
    "        loss = criterion(outputs.view(-1, vocab_size), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b353dd2-b644-4d4a-8734-3b51088eb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "def generate_response(prompt, max_length=50, top_k=10):\n",
    "    model.eval()\n",
    "    input_text = prompt\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "    generated = input_ids.clone()\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(generated)\n",
    "            next_token_logits = outputs[:, -1, :]\n",
    "\n",
    "            probs = F.softmax(next_token_logits, dim=-1)\n",
    "            top_k_probs, top_k_indices = torch.topk(probs, k=top_k, dim=-1)\n",
    "            next_token = top_k_indices[0, torch.multinomial(top_k_probs[0], 1)].unsqueeze(0)\n",
    "\n",
    "        generated = torch.cat((generated, next_token), dim=1)\n",
    "\n",
    "        if next_token.item() == tokenizer.eos_token_id:\n",
    "            break\n",
    "\n",
    "    response = tokenizer.decode(generated[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "    return response.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd36aaa6-c5be-40c2-a6c8-cb8e59a0a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Response:\", generate_response(\"Q: What is 7 + 5?\\nA:\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67010098-9ace-40ff-bc41-84a68b0a6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, AutoTokenizer\n",
    "\n",
    "print(\"Loading model...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Use EOS token for padding\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained(\"distilgpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd29e3-7d67-4737-b1c2-5dd9014f45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load your cleaned Q/A dataset from before\n",
    "with open(\"qa_decoder_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = [json.loads(line)[\"text\"] for line in f]\n",
    "\n",
    "# Join each Q/A into a single large training string\n",
    "dataset_texts = \"\\n\\n\".join(lines)\n",
    "print(\"Loaded and formatted dataset.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1f631-a1ac-4622-9267-e90bafe95cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2QADataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs = []\n",
    "\n",
    "        # Tokenize the whole dataset and flatten it\n",
    "        tokens = tokenizer(text, return_tensors=\"pt\", truncation=False)[\"input_ids\"][0]\n",
    "\n",
    "        # Split into 1024-token chunks\n",
    "        for i in range(0, len(tokens) - max_length, max_length):\n",
    "            chunk = tokens[i:i+max_length]\n",
    "            self.inputs.append(chunk)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.inputs[idx]\n",
    "        return input_ids, input_ids  # (input, label) pair\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad16a5-3b57-450d-baff-486d0c8cbd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GPT2QADataset(dataset_texts, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "print(\"Dataset ready with\", len(train_dataset), \"samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd1317-5e61-43d3-a0cb-08fbd1bcde59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2QADataset(Dataset):\n",
    "    def __init__(self, text, tokenizer, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs = []\n",
    "\n",
    "        # Tokenize the whole dataset and flatten it\n",
    "        tokens = tokenizer(text, return_tensors=\"pt\", truncation=False)[\"input_ids\"][0]\n",
    "\n",
    "        # Split into 1024-token chunks\n",
    "        for i in range(0, len(tokens) - max_length, max_length):\n",
    "            chunk = tokens[i:i+max_length]\n",
    "            self.inputs.append(chunk)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.inputs[idx]\n",
    "        return input_ids, input_ids  # input = label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd20915-2070-4548-85d5-5fefcb666204",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GPT2QADataset(dataset_texts, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "print(\"Dataset ready with\", len(train_dataset), \"samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fd6175d4-fb5b-4f42-a058-1a448a5008a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting quick test loop...\n",
      "Step 0 | Loss: 0.4381\n",
      "Step 1 | Loss: 0.4323\n",
      "Step 2 | Loss: 0.4551\n",
      "Step 3 | Loss: 0.3939\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "\n",
    "model.train()\n",
    "print(\"Starting quick test loop...\")\n",
    "\n",
    "for step, (input_ids, labels) in enumerate(train_loader):\n",
    "    if step > 3:  # Just 4 steps to test training\n",
    "        break\n",
    "\n",
    "    input_ids = input_ids.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_ids, labels=labels)\n",
    "    loss = outputs.loss\n",
    "\n",
    "    print(f\"Step {step} | Loss: {loss.item():.4f}\")\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f671b4a2-6461-4232-b799-acccade01bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_loader = DataLoader(train_dataset[:20], batch_size=2, shuffle=True)\n",
    "print(\"Subset DataLoader ready with 20 samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f6673-8dd4-4e6e-b39b-6ed06ada2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "subset = Subset(train_dataset, list(range(20)))  # first 20 examples\n",
    "subset_loader = DataLoader(subset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d28fcf-ef7d-407b-81c0-fe931d84b43e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
    "\n",
    "    for input_ids, labels in subset_loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(subset_loader)\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895b77d3-a51b-4926-8ac1-007829c18cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, max_new_tokens=50):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],  # <-- Fix added here\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "589678c9-a5e2-40ae-a6cd-4d5f9f89f3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Who wrote Hamlet?\n",
      "A: William Shakespeare\n",
      "Q: What is the capital of India?\n",
      "A: New Delhi\n",
      "Q: What is the capital of India?\n",
      "A: New Delhi\n",
      "Q: Who wrote Hamlet?\n",
      "A: William Shakespeare\n",
      "\n",
      "Q: What\n",
      "Q: What is the capital of India?\n",
      "A: New Delhi\n",
      "\n",
      "Q: What is the square of 2?\n",
      "A: 64\n",
      "\n",
      "Q: Is 'run' a verb in 'I run daily'?\n",
      "A: Yes\n",
      "\n",
      "Q: What is the past tense of 'eat'?\n",
      "Q: What is the boiling point of water?\n",
      "A: 100°C\n",
      "Q: What is the boiling point of water?\n",
      "A: 100°C\n",
      "Q: What is the largest planet?\n",
      "A: Jupiter\n",
      "Q: Is 'run' a verb in 'I run daily'?\n",
      "A\n",
      "Q: Give a synonym for 'smart'.\n",
      "A: Intelligent\n",
      "Q: What is the cube of 9?\n",
      "A: 256\n",
      "\n",
      "Q: What is the capital of India?\n",
      "A: New Delhi\n",
      "\n",
      "Q: What is the largest planet?\n",
      "A: Jupiter\n",
      "\n",
      "Q: What\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(generate_response(\"Q: Who wrote Hamlet?\\nA:\"))\n",
    "print(generate_response(\"Q: What is the capital of India?\\nA:\"))\n",
    "print(generate_response(\"Q: What is the boiling point of water?\\nA:\"))\n",
    "print(generate_response(\"Q: Give a synonym for 'smart'.\\nA:\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a79029f3-fb35-4ffd-894a-09b6b4531013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\ferna\n",
      "Contents:\n",
      "['-1.14-windows.xml', '.anaconda', '.cache', '.conda', '.condarc', '.continuum', '.idlerc', '.ipynb_checkpoints', '.ipython', '.jupyter', '.Ld9VirtualBox', '.node_repl_history', '.openjfx', '.vscode', '3D Objects', 'anaconda3', 'anaconda_projects', 'ansel', 'AppData', 'Application Data', 'bluej', 'BrawlhallaReplays', 'ceaser.py', 'cleaned_dataset.json', 'Contacts', 'Cookies', 'diffie hellman.py', 'Documents', 'Downloads', 'Favorites', 'from Crypto.py', 'generated_dataset.json', 'IntelGraphicsProfiles', 'Links', 'llama2_test.py', 'llm project 2.ipynb', 'llm project.ipynb', 'llm-env', 'Local Settings', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{f591b2a5-fa68-11ef-a828-b301f62e9121}.TM.blf', 'NTUSER.DAT{f591b2a5-fa68-11ef-a828-b301f62e9121}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{f591b2a5-fa68-11ef-a828-b301f62e9121}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'OpenVPN', 'primalarity.py', 'PrintHood', 'qa_clean_dataset.json', 'qa_decoder_dataset.json', 'random', 'Recent', 'Recorded Calls', 'Saved Games', 'Searches', 'SendTo', 'Start Menu', 'Templates', 'TicTacToe', 'Untitled.ipynb', 'Untitled1.ipynb', 'Videos']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List all files and folders in the current working directory\n",
    "print(\"Current Directory:\", os.getcwd())\n",
    "print(\"Contents:\")\n",
    "print(os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "80a08b31-59a1-4efd-9d2e-e199af8b80e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('output\\\\tokenizer_config.json',\n",
       " 'output\\\\special_tokens_map.json',\n",
       " 'output\\\\vocab.json',\n",
       " 'output\\\\merges.txt',\n",
       " 'output\\\\added_tokens.json',\n",
       " 'output\\\\tokenizer.json')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to 'output/' directory\n",
    "model.save_pretrained(\"output\")\n",
    "\n",
    "# Save the tokenizer to the same folder\n",
    "tokenizer.save_pretrained(\"output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fff5d9a4-74df-4c99-8d23-04c745a349c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['config.json', 'generation_config.json', 'merges.txt', 'model.safetensors', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json', 'vocab.json']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"output\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8d9aefd0-33a9-4e13-8242-0da480c4dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Easy Prompt Responses -----\n",
      "\n",
      "1. Q: What is 2 + 2?\n",
      "A:\n",
      "   Response: A: 2, 4\n",
      "\n",
      "Q: What is the past tense of 'eat'?\n",
      "A: Ate\n",
      "Q: Is 'run' a verb in 'I run daily'?\n",
      "\n",
      "2. Q: What is the capital of India?\n",
      "A:\n",
      "   Response: New Delhi\n",
      "\n",
      "Q: What is the capital of India?\n",
      "A: New Delhi\n",
      "\n",
      "Q: If A > B and B > C, is A > C?\n",
      "A\n",
      "\n",
      "3. Q: What is 5 - 3?\n",
      "A:\n",
      "   Response: 4\n",
      "Q: Who invented the light bulb?\n",
      "A: William Shakespeare\n",
      "Q: What is H2O commonly known as?\n",
      "A: Water\n",
      "Q: Who discovered gravity?\n",
      "\n",
      "4. Q: What is the opposite of hot?\n",
      "A:\n",
      "   Response: Cool\n",
      "\n",
      "Q: Is 'quickly' a noun or adverb?\n",
      "A: Adverb\n",
      "\n",
      "Q: If A > B and B > C, is A > C\n",
      "\n",
      "5. Q: Who wrote Hamlet?\n",
      "A:\n",
      "   Response: William Shakespeare\n",
      "\n",
      "Q: What is the currency of Japan?\n",
      "A: Yen\n",
      "\n",
      "Q: What is the square of 6?\n",
      "A: 944\n",
      "Q: Give a synonym\n",
      "\n",
      "6. Q: What is the boiling point of water?\n",
      "A:\n",
      "   Response: 100°C\n",
      "Q: Is 'quickly' the currency of Japan?\n",
      "A: Yen\n",
      "Q: What is 34 * 2?\n",
      "A: 44\n",
      "Q: If\n",
      "\n",
      "7. Q: What comes after 3, 4, 5?\n",
      "A:\n",
      "   Response: 10 + 19\n",
      "\n",
      "Q: Who discovered gravity?\n",
      "A: Isaac Newton\n",
      "\n",
      "Q: What is H2O commonly known as?\n",
      "A: Water\n",
      "\n",
      "Q\n",
      "\n",
      "8. Q: What color is the sky?\n",
      "A:\n",
      "   Response: Violet\n",
      "Q: Who wrote Hamlet?\n",
      "A: William Shakespeare\n",
      "Q: If you have 4 apples and give away 2, how many are left?\n",
      "A: 2\n",
      "Q:\n",
      "\n",
      "9. Q: How many days are there in a week?\n",
      "A:\n",
      "   Response: 2183\n",
      "Q: What do plants absorb?\n",
      "A: Carbon dioxide\n",
      "Q: If you have 4 apples and give away 2, how many are left?\n",
      "A:\n",
      "\n",
      "10. Q: What is the capital of Japan?\n",
      "A:\n",
      "   Response: New Delhi\n",
      "Q: What is the square of 8?\n",
      "A: 2\n",
      "Q: What comes after 2, 4, 6, 8?\n",
      "A: 10\n",
      "Q: What\n",
      "\n",
      "11. Q: What is 10 ÷ 2?\n",
      "A:\n",
      "   Response: 2 * 100\n",
      "\n",
      "Q: If you have 4 apples and give away 2, how many are left?\n",
      "A: 2\n",
      "\n",
      "Q: Who invented the light bulb?\n",
      "A\n",
      "\n",
      "12. Q: What is H2O commonly known as?\n",
      "A:\n",
      "   Response: Water\n",
      "\n",
      "Q: Is 'quickly' a noun or adverb?\n",
      "A: Adverb\n",
      "Q: What is the square of 31?\n",
      "A: 49\n",
      "\n",
      "13. Q: What is the plural of cat?\n",
      "A:\n",
      "   Response: Mother Nature\n",
      "Q: What is the largest planet?\n",
      "A: Jupiter\n",
      "\n",
      "Q: What is the square of 31?\n",
      "A: 4958\n",
      "\n",
      "Q: Who invented the\n",
      "\n",
      "14. Q: How many wheels does a car have?\n",
      "A:\n",
      "   Response: 9\n",
      "Q: Who wrote Hamlet?\n",
      "A: William Shakespeare\n",
      "\n",
      "Q: What is the square of 8?\n",
      "A: 121\n",
      "\n",
      "Q: Is every even number\n",
      "\n",
      "15. Q: What is 6 × 3?\n",
      "A:\n",
      "   Response: 100\n",
      "Q: What is 29 * 22?\n",
      "A: 25\n",
      "Q: What is the largest planet?\n",
      "A: Jupiter\n",
      "Q: Is every even number divisible by 2?\n",
      "\n",
      "16. Q: What is the capital of France?\n",
      "A:\n",
      "   Response: London\n",
      "Q: What is the capital of India?\n",
      "A: New Delhi\n",
      "Q: Is 'run' a verb in 'I run daily'?\n",
      "A: Yes\n",
      "Q:\n",
      "\n",
      "17. Q: What is the past tense of eat?\n",
      "A:\n",
      "   Response: Ate\n",
      "Q: If you have 4 apples and give away 2, how many are left?\n",
      "A: 2\n",
      "\n",
      "Q: What is 46 - 28?\n",
      "A:\n",
      "\n",
      "18. Q: What is the opposite of big?\n",
      "A:\n",
      "   Response: Yes\n",
      "\n",
      "Q: What is the number of calories you have in a serving?\n",
      "A: 100\n",
      "\n",
      "Q: What is the boiling point of water?\n",
      "A: 100°\n",
      "\n",
      "19. Q: How many legs does a spider have?\n",
      "A:\n",
      "   Response: 2\n",
      "Q: Who wrote Hamlet?\n",
      "A: William Shakespeare\n",
      "\n",
      "Q: What is the largest planet?\n",
      "A: Jupiter\n",
      "\n",
      "Q: Is 'run' a\n",
      "\n",
      "20. Q: What is the color of a banana?\n",
      "A:\n",
      "   Response: green\n",
      "\n",
      "Q: Is 'quickly' a noun or adverb?\n",
      "A: Adverb\n",
      "\n",
      "Q: What is the cube of 9?\n",
      "A: 1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load model and tokenizer from local fine-tuned folder\n",
    "model = GPT2LMHeadModel.from_pretrained(\"output\", local_files_only=True)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"output\", local_files_only=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "easy_prompts = [\n",
    "    \"Q: What is 2 + 2?\\nA:\",\n",
    "    \"Q: What is the capital of India?\\nA:\",\n",
    "    \"Q: What is 5 - 3?\\nA:\",\n",
    "    \"Q: What is the opposite of hot?\\nA:\",\n",
    "    \"Q: Who wrote Hamlet?\\nA:\",\n",
    "    \"Q: What is the boiling point of water?\\nA:\",\n",
    "    \"Q: What comes after 3, 4, 5?\\nA:\",\n",
    "    \"Q: What color is the sky?\\nA:\",\n",
    "    \"Q: How many days are there in a week?\\nA:\",\n",
    "    \"Q: What is the capital of Japan?\\nA:\",\n",
    "    \"Q: What is 10 ÷ 2?\\nA:\",\n",
    "    \"Q: What is H2O commonly known as?\\nA:\",\n",
    "    \"Q: What is the plural of cat?\\nA:\",\n",
    "    \"Q: How many wheels does a car have?\\nA:\",\n",
    "    \"Q: What is 6 × 3?\\nA:\",\n",
    "    \"Q: What is the capital of France?\\nA:\",\n",
    "    \"Q: What is the past tense of eat?\\nA:\",\n",
    "    \"Q: What is the opposite of big?\\nA:\",\n",
    "    \"Q: How many legs does a spider have?\\nA:\",\n",
    "    \"Q: What is the color of a banana?\\nA:\"\n",
    "]\n",
    "\n",
    "\n",
    "def generate_response(prompt, max_length=50):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            top_k=50\n",
    "        )\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response[len(prompt):].strip()\n",
    "\n",
    "print(\"----- Easy Prompt Responses -----\\n\")\n",
    "for i, prompt in enumerate(easy_prompts, 1):\n",
    "    response = generate_response(prompt)\n",
    "    print(f\"{i}. {prompt.strip()}\\n   Response: {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d2bec8b1-c38f-484f-ae8a-f90f1e1fc0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. ❌ Expected: 4 | Got: a + 2\n",
      "q: who discovered gravity?\n",
      "a: isaac newton\n",
      "\n",
      "q: what is the cube of light?\n",
      "a: 1028\n",
      "\n",
      "q: is 121 a square\n",
      "2.  Expected: new delhi | Got: new delhi\n",
      "q: is 'run' a verb in 'i run daily'?\n",
      "a: yes\n",
      "q: what is the boiling point of water?\n",
      "a: 100°c\n",
      "3.  Expected: 2 | Got: 5\n",
      "q: what is the square of 12?\n",
      "a: 9\n",
      "q: what is the square of 5?\n",
      "a: 622\n",
      "q: what is 8 * 21?\n",
      "4. ❌ Expected: cold | Got: water\n",
      "\n",
      "q: what is the opposite of hot?\n",
      "a: water\n",
      "\n",
      "q: what is the cube of 10?\n",
      "a: 361\n",
      "\n",
      "q: what is the\n",
      "5.  Expected: william shakespeare | Got: william shakespeare\n",
      "q: is every even number divisible by 2?\n",
      "a: yes\n",
      "q: who wrote hamlet?\n",
      "a: william shakespeare\n",
      "q: if a > b and b\n",
      "6.  Expected: 100°c | Got: 100°c\n",
      "\n",
      "q: what is the square of 9?\n",
      "a: 2\n",
      "\n",
      "q: what is the boiling point of water?\n",
      "a: 100°c\n",
      "7.  Expected: 6 | Got: 10\n",
      "q: is every even number divisible by 2?\n",
      "a: yes\n",
      "q: what comes after 2, 4, 6?\n",
      "a: 10\n",
      "\n",
      "q\n",
      "8. ❌ Expected: blue | Got: orange\n",
      "\n",
      "q: what is the past tense of 'eat'?\n",
      "a: ate\n",
      "\n",
      "q: what is 38 - 28?\n",
      "a: 27\n",
      "\n",
      "q: what comes\n",
      "9.  Expected: 7 | Got: 43\n",
      "q: aq - -2\n",
      "a: what is the cube of 23?\n",
      "a: 2732\n",
      "q: what gas do plants absorb?\n",
      "a:\n",
      "10. ❌ Expected: tokyo | Got: new delhi\n",
      "q: what is the opposite of 'happy'?\n",
      "a: sad\n",
      "q: is 'happy'?\n",
      "a: sad\n",
      "q: what is the currency of japan?\n",
      "11. ❌ Expected: 5 | Got: 2\n",
      "q: what is the temperature of india?\n",
      "a: 100°c\n",
      "\n",
      "q: if you have 3 apples and give away 4, how many are left?\n",
      "a\n",
      "12.  Expected: water | Got: water\n",
      "q: is 'quickly' a verb in 'i often have a dish' or a dish?\n",
      "a: yes\n",
      "\n",
      "q: what is the square of\n",
      "13. ❌ Expected: cats | Got: son of god\n",
      "q: what is the past tense of 'eat'?\n",
      "a: ate\n",
      "q: what is the opposite of 'eat'?\n",
      "a: ate\n",
      "q\n",
      "14.  Expected: 4 | Got: 2\n",
      "so: 13\n",
      "a: 10\n",
      "q: if you have 4 apples and give away 2, how many are left?\n",
      "a: 1\n",
      "\n",
      "q: what is\n",
      "15. ❌ Expected: 18 | Got: 5\n",
      "q: what organ pumps blood in the human body?\n",
      "a: heart\n",
      "\n",
      "q: who invented the light bulb?\n",
      "a: william shakespeare\n",
      "\n",
      "q: who invented the\n",
      "16. ❌ Expected: paris | Got: new delhi\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is 4 - 17?\n",
      "a: 4428 * 2328\n",
      "\n",
      "q:\n",
      "17.  Expected: ate | Got: ate\n",
      "q: what is the currency of japan?\n",
      "a: yen\n",
      "\n",
      "q: what is the largest planet?\n",
      "a: jupiter\n",
      "\n",
      "q: what is the\n",
      "18. ❌ Expected: small | Got: sad\n",
      "q: what is the opposite of gas?\n",
      "a: carbon dioxide\n",
      "q: what is the largest planet?\n",
      "a: jupiter\n",
      "q: is every even number divisible\n",
      "19. ❌ Expected: 8 | Got: 25\n",
      "q: what is 9 - 22?\n",
      "a: 33\n",
      "q: if you have 4 apples and give away 2, how many are left?\n",
      "a: 2\n",
      "20. ❌ Expected: yellow | Got: green\n",
      "\n",
      "q: what is the cube of 1?\n",
      "a: 1\n",
      "\n",
      "q: if a > b and b > c, is a > c?\n",
      "a:\n",
      "\n",
      "Overall Accuracy: 45.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "expected_answers = [\n",
    "    \"4\",\n",
    "    \"New Delhi\",\n",
    "    \"2\",\n",
    "    \"cold\",\n",
    "    \"William Shakespeare\",\n",
    "    \"100°C\",\n",
    "    \"6\",\n",
    "    \"blue\",\n",
    "    \"7\",\n",
    "    \"Tokyo\",\n",
    "    \"5\",\n",
    "    \"water\",\n",
    "    \"cats\",\n",
    "    \"4\",\n",
    "    \"18\",\n",
    "    \"Paris\",\n",
    "    \"ate\",\n",
    "    \"small\",\n",
    "    \"8\",\n",
    "    \"yellow\"\n",
    "]\n",
    "\n",
    "\n",
    "easy_prompts = [\n",
    "    \"Q: What is 2 + 2?\\nA:\",\n",
    "    \"Q: What is the capital of India?\\nA:\",\n",
    "    \"Q: What is 5 - 3?\\nA:\",\n",
    "    \"Q: What is the opposite of hot?\\nA:\",\n",
    "    \"Q: Who wrote Hamlet?\\nA:\",\n",
    "    \"Q: What is the boiling point of water?\\nA:\",\n",
    "    \"Q: What comes after 3, 4, 5?\\nA:\",\n",
    "    \"Q: What color is the sky?\\nA:\",\n",
    "    \"Q: How many days are there in a week?\\nA:\",\n",
    "    \"Q: What is the capital of Japan?\\nA:\",\n",
    "    \"Q: What is 10 ÷ 2?\\nA:\",\n",
    "    \"Q: What is H2O commonly known as?\\nA:\",\n",
    "    \"Q: What is the plural of cat?\\nA:\",\n",
    "    \"Q: How many wheels does a car have?\\nA:\",\n",
    "    \"Q: What is 6 × 3?\\nA:\",\n",
    "    \"Q: What is the capital of France?\\nA:\",\n",
    "    \"Q: What is the past tense of eat?\\nA:\",\n",
    "    \"Q: What is the opposite of big?\\nA:\",\n",
    "    \"Q: How many legs does a spider have?\\nA:\",\n",
    "    \"Q: What is the color of a banana?\\nA:\"\n",
    "]\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for i, prompt in enumerate(easy_prompts):\n",
    "    response = generate_response(prompt).lower().strip()\n",
    "    expected = expected_answers[i].lower().strip()\n",
    "\n",
    "    if expected in response:\n",
    "        correct += 1\n",
    "    print(f\"{i+1}. \" if expected in response else f\"{i+1}. ❌\", f\"Expected: {expected} | Got: {response}\")\n",
    "\n",
    "\n",
    "accuracy = correct / len(expected_answers) * 100\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8c6383f9-37a2-4a79-af5a-f904f3a6c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"output\", local_files_only=True)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"output\", local_files_only=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Updated prompt generator (Greedy decoding, normalized, shorter length)\n",
    "def generate_response(prompt, max_length=30):\n",
    "    # Normalize format\n",
    "    prompt = prompt.strip()\n",
    "    if not prompt.startswith(\"Q:\"):\n",
    "        prompt = f\"Q: {prompt}\"\n",
    "    if not prompt.endswith(\"A:\"):\n",
    "        prompt += \"\\nA:\"\n",
    "    \n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=input_ids.shape[1] + max_length,\n",
    "            do_sample=False,  # greedy decoding\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded[len(prompt):].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "146b756d-d805-4c08-894e-8bc4273cdec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Improved Model Accuracy Test -----\n",
      "\n",
      "1. yes Prompt: What is the capital of India?\n",
      "   Expected: new delhi | Response: new delhi\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is the capital of india?\n",
      "a:\n",
      "\n",
      "2. no Prompt: What is the capital of Japan?\n",
      "   Expected: tokyo | Response: new delhi\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is the capital of india?\n",
      "a:\n",
      "\n",
      "3. no Prompt: What is the capital of France?\n",
      "   Expected: paris | Response: new delhi\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is the capital of india?\n",
      "a:\n",
      "\n",
      "4. yes Prompt: What is H2O commonly known as?\n",
      "   Expected: water | Response: water\n",
      "q: what is the boiling point of water?\n",
      "a: 100°c\n",
      "\n",
      "q: what is the boiling point of water?\n",
      "\n",
      "5. yes Prompt: Who wrote Hamlet?\n",
      "   Expected: william shakespeare | Response: william shakespeare\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is the capital of india?\n",
      "a:\n",
      "\n",
      "6. yes Prompt: What is the opposite of happy?\n",
      "   Expected: sad | Response: sad\n",
      "q: what is the opposite of happy?\n",
      "a: sad\n",
      "q: what is the opposite of happy?\n",
      "a: sad\n",
      "\n",
      "7. yes Prompt: What is the boiling point of water?\n",
      "   Expected: 100°c | Response: 100°c\n",
      "\n",
      "q: what is the boiling point of water?\n",
      "a: 100°c\n",
      "\n",
      "q: what is the boiling point\n",
      "\n",
      "8. yes Prompt: What is the past tense of eat?\n",
      "   Expected: ate | Response: ate\n",
      "q: what is the past tense of 'eat'?\n",
      "a: ate\n",
      "q: what is the past tense of 'eat\n",
      "\n",
      "9. yes Prompt: Give a synonym for smart.\n",
      "   Expected: intelligent | Response: intelligent\n",
      "q: what is the opposite of 'happy'?\n",
      "a: sad\n",
      "q: what is the opposite of 'happy'?\n",
      "a:\n",
      "\n",
      "10. no Prompt: What is the color of the sky?\n",
      "   Expected: blue | Response: green\n",
      "q: what is the square of 10?\n",
      "a: 100\n",
      "q: what is the square of 10?\n",
      "a: 100\n",
      "\n",
      "\n",
      "Final Accuracy: 70.00%\n"
     ]
    }
   ],
   "source": [
    "# Define simple test prompts and expected answers\n",
    "test_prompts = [\n",
    "    \"What is the capital of India?\",\n",
    "    \"What is the capital of Japan?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is H2O commonly known as?\",\n",
    "    \"Who wrote Hamlet?\",\n",
    "    \"What is the opposite of happy?\",\n",
    "    \"What is the boiling point of water?\",\n",
    "    \"What is the past tense of eat?\",\n",
    "    \"Give a synonym for smart.\",\n",
    "    \"What is the color of the sky?\",\n",
    "]\n",
    "\n",
    "expected_answers = [\n",
    "    \"New Delhi\",\n",
    "    \"Tokyo\",\n",
    "    \"Paris\",\n",
    "    \"Water\",\n",
    "    \"William Shakespeare\",\n",
    "    \"Sad\",\n",
    "    \"100°C\",\n",
    "    \"Ate\",\n",
    "    \"Intelligent\",\n",
    "    \"Blue\"\n",
    "]\n",
    "\n",
    "# Evaluation loop\n",
    "correct = 0\n",
    "\n",
    "print(\"----- Improved Model Accuracy Test -----\\n\")\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    response = generate_response(prompt).lower().strip()\n",
    "    expected = expected_answers[i].lower().strip()\n",
    "    \n",
    "    # Soft match: expected keyword appears in model output\n",
    "    is_correct = expected in response\n",
    "    print(f\"{i+1}. {'yes' if is_correct else 'no'} Prompt: {prompt}\\n   Expected: {expected} | Response: {response}\\n\")\n",
    "    \n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(expected_answers) * 100\n",
    "print(f\"\\nFinal Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "53610754-28ce-4134-9f21-7324b205605f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Instruction/Response Format Accuracy Test -----\n",
      "\n",
      "1. yes Prompt: What is the capital of India?\n",
      "   Expected: new delhi | Response: yes\n",
      "\n",
      "q: what is the capital of india?\n",
      "answer: new delhi\n",
      "\n",
      "q: what is the capital of india?\n",
      "answer\n",
      "\n",
      "2. no Prompt: What is the capital of Japan?\n",
      "   Expected: tokyo | Response: yes\n",
      "\n",
      "q: what is the capital of india?\n",
      "answer: new delhi\n",
      "\n",
      "q: what is the capital of india?\n",
      "answer\n",
      "\n",
      "3. no Prompt: What is the capital of France?\n",
      "   Expected: paris | Response: yes\n",
      "\n",
      "q: what is the capital of india?\n",
      "answer: new delhi\n",
      "\n",
      "q: what is the capital of india?\n",
      "answer\n",
      "\n",
      "4. no Prompt: What is H2O commonly known as?\n",
      "   Expected: water | Response: yes\n",
      "\n",
      "q: what is the currency of japan?\n",
      "a: yen\n",
      "\n",
      "q: what is the currency of japan?\n",
      "a:\n",
      "\n",
      "5. no Prompt: Who wrote Hamlet?\n",
      "   Expected: william shakespeare | Response: yes\n",
      "\n",
      "q: what is the cube of 12?\n",
      "a: 1728\n",
      "\n",
      "q: what is the cube of 12?\n",
      "a\n",
      "\n",
      "6. yes Prompt: What is the opposite of happy?\n",
      "   Expected: sad | Response: yes\n",
      "\n",
      "q: what is the opposite of sad?\n",
      "answer: yes\n",
      "\n",
      "q: what is the opposite of happy?\n",
      "answer:\n",
      "\n",
      "7. yes Prompt: What is the boiling point of water?\n",
      "   Expected: 100°c | Response: yes\n",
      "\n",
      "q: what is the boiling point of water?\n",
      "answer: 100°c\n",
      "\n",
      "q: what is the boiling point of water\n",
      "\n",
      "8. no Prompt: What is the past tense of eat?\n",
      "   Expected: ate | Response: yes\n",
      "\n",
      "q: what is the past tense of 'eat'?\n",
      "answer: yes\n",
      "\n",
      "q: what is the past tense of 'eat\n",
      "\n",
      "9. no Prompt: Give a synonym for smart.\n",
      "   Expected: intelligent | Response: yes\n",
      "\n",
      "q: what is the square of 10?\n",
      "a: 2\n",
      "\n",
      "q: what is the square of 10?\n",
      "a:\n",
      "\n",
      "10. no Prompt: What is the color of the sky?\n",
      "   Expected: blue | Response: yes\n",
      "\n",
      "q: what is the opposite of 'happy'?\n",
      "answer: yes\n",
      "\n",
      "q: what is the opposite of 'happy'?\n",
      "\n",
      "\n",
      "Final Accuracy (Instruction/Response): 30.00%\n"
     ]
    }
   ],
   "source": [
    "def generate_response_instruction(prompt, max_length=30):\n",
    "    # Match the 'Instruction/Response' format\n",
    "    prompt = prompt.strip()\n",
    "    if not prompt.startswith(\"Instruction:\"):\n",
    "        prompt = f\"Instruction: {prompt}\"\n",
    "    if \"Response:\" not in prompt:\n",
    "        prompt += \"\\nResponse:\"\n",
    "    \n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=input_ids.shape[1] + max_length,\n",
    "            do_sample=False,  # Greedy decoding\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded.split(\"Response:\")[-1].strip()\n",
    "\n",
    "# Prompts\n",
    "instruction_prompts = [\n",
    "    \"What is the capital of India?\",\n",
    "    \"What is the capital of Japan?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is H2O commonly known as?\",\n",
    "    \"Who wrote Hamlet?\",\n",
    "    \"What is the opposite of happy?\",\n",
    "    \"What is the boiling point of water?\",\n",
    "    \"What is the past tense of eat?\",\n",
    "    \"Give a synonym for smart.\",\n",
    "    \"What is the color of the sky?\"\n",
    "]\n",
    "\n",
    "expected_answers = [\n",
    "    \"New Delhi\",\n",
    "    \"Tokyo\",\n",
    "    \"Paris\",\n",
    "    \"Water\",\n",
    "    \"William Shakespeare\",\n",
    "    \"Sad\",\n",
    "    \"100°C\",\n",
    "    \"Ate\",\n",
    "    \"Intelligent\",\n",
    "    \"Blue\"\n",
    "]\n",
    "\n",
    "# Accuracy Test\n",
    "correct = 0\n",
    "print(\"----- Instruction/Response Format Accuracy Test -----\\n\")\n",
    "for i, prompt in enumerate(instruction_prompts):\n",
    "    response = generate_response_instruction(prompt).lower().strip()\n",
    "    expected = expected_answers[i].lower().strip()\n",
    "    is_correct = expected in response\n",
    "    print(f\"{i+1}. {'yes' if is_correct else 'no'} Prompt: {prompt}\\n   Expected: {expected} | Response: {response}\\n\")\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(expected_answers) * 100\n",
    "print(f\"\\nFinal Accuracy (Instruction/Response): {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "89482b34-064c-4ff4-9bc5-43cdac48f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Reverting to Q/A Format (Best Accuracy) -----\n",
      "\n",
      "1. yes Prompt: What is the capital of India?\n",
      "   Expected: new delhi | Response: new delhi\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is the capital of india?\n",
      "a:\n",
      "\n",
      "2. no Prompt: What is the capital of Japan?\n",
      "   Expected: tokyo | Response: new delhi\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is the capital of india?\n",
      "a:\n",
      "\n",
      "3. no Prompt: What is the capital of France?\n",
      "   Expected: paris | Response: new delhi\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is the capital of india?\n",
      "a:\n",
      "\n",
      "4. yes Prompt: What is H2O commonly known as?\n",
      "   Expected: water | Response: water\n",
      "q: what is the boiling point of water?\n",
      "a: 100°c\n",
      "\n",
      "q: what is the boiling point of water?\n",
      "\n",
      "5. yes Prompt: Who wrote Hamlet?\n",
      "   Expected: william shakespeare | Response: william shakespeare\n",
      "q: what is the capital of india?\n",
      "a: new delhi\n",
      "q: what is the capital of india?\n",
      "a:\n",
      "\n",
      "6. yes Prompt: What is the opposite of happy?\n",
      "   Expected: sad | Response: sad\n",
      "q: what is the opposite of happy?\n",
      "a: sad\n",
      "q: what is the opposite of happy?\n",
      "a: sad\n",
      "\n",
      "7. yes Prompt: What is the boiling point of water?\n",
      "   Expected: 100°c | Response: 100°c\n",
      "\n",
      "q: what is the boiling point of water?\n",
      "a: 100°c\n",
      "\n",
      "q: what is the boiling point\n",
      "\n",
      "8. yes Prompt: What is the past tense of eat?\n",
      "   Expected: ate | Response: ate\n",
      "q: what is the past tense of 'eat'?\n",
      "a: ate\n",
      "q: what is the past tense of 'eat\n",
      "\n",
      "9. yes Prompt: Give a synonym for smart.\n",
      "   Expected: intelligent | Response: intelligent\n",
      "q: what is the opposite of 'happy'?\n",
      "a: sad\n",
      "q: what is the opposite of 'happy'?\n",
      "a:\n",
      "\n",
      "10. no Prompt: What is the color of the sky?\n",
      "   Expected: blue | Response: green\n",
      "q: what is the square of 10?\n",
      "a: 100\n",
      "q: what is the square of 10?\n",
      "a: 100\n",
      "\n",
      "\n",
      "📊 Final Accuracy (Q/A format): 70.00%\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt, max_length=30):\n",
    "    # Ensure Q/A format is consistent\n",
    "    prompt = prompt.strip()\n",
    "    if not prompt.startswith(\"Q:\"):\n",
    "        prompt = f\"Q: {prompt}\"\n",
    "    if not prompt.endswith(\"A:\"):\n",
    "        prompt += \"\\nA:\"\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=input_ids.shape[1] + max_length,\n",
    "            do_sample=False,  # Greedy decoding\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return decoded[len(prompt):].strip()\n",
    "\n",
    "# Your best-performing prompt list\n",
    "test_prompts = [\n",
    "    \"What is the capital of India?\",\n",
    "    \"What is the capital of Japan?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"What is H2O commonly known as?\",\n",
    "    \"Who wrote Hamlet?\",\n",
    "    \"What is the opposite of happy?\",\n",
    "    \"What is the boiling point of water?\",\n",
    "    \"What is the past tense of eat?\",\n",
    "    \"Give a synonym for smart.\",\n",
    "    \"What is the color of the sky?\"\n",
    "]\n",
    "\n",
    "expected_answers = [\n",
    "    \"New Delhi\",\n",
    "    \"Tokyo\",\n",
    "    \"Paris\",\n",
    "    \"Water\",\n",
    "    \"William Shakespeare\",\n",
    "    \"Sad\",\n",
    "    \"100°C\",\n",
    "    \"Ate\",\n",
    "    \"Intelligent\",\n",
    "    \"Blue\"\n",
    "]\n",
    "\n",
    "# Evaluation\n",
    "correct = 0\n",
    "print(\"----- Reverting to Q/A Format (Best Accuracy) -----\\n\")\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    response = generate_response(prompt).lower().strip()\n",
    "    expected = expected_answers[i].lower().strip()\n",
    "    is_correct = expected in response\n",
    "    print(f\"{i+1}. {'yes' if is_correct else 'no'} Prompt: {prompt}\\n   Expected: {expected} | Response: {response}\\n\")\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(expected_answers) * 100\n",
    "print(f\"\\n📊 Final Accuracy (Q/A format): {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eace50-c3fd-4961-afa3-be13001daca3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
